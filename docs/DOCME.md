# Documents
1. Convolution Subsampling: [link](https://www.tutorialexample.com/understand-convolution-subsampling-module-in-conformer-deep-learning-tutorial/)
2. Conv Subsampling: [link](https://blog.csdn.net/ldy007714/article/details/127086170?ops_request_misc=%257B%2522request%255Fid%2522%253A%2522171118103416800184166564%2522%252C%2522scm%2522%253A%252220140713.130102334..%2522%257D&request_id=171118103416800184166564&biz_id=0&spm=1018.2226.3001.4187)
3. Separable Convolution: [link](https://towardsdatascience.com/a-basic-introduction-to-separable-convolutions-b99ec3102728)
4. Separable Convolution: [link](https://blog.csdn.net/yyp1998/article/details/121048613?spm=1001.2101.3001.4242.1&utm_relevant_index=3)
5. DepthWise: [link](https://www.youtube.com/watch?v=ftc7rj7kzQ0)
6. DepthWise-tt: [link](DepthWise: [link](https://www.youtube.com/watch?v=ftc7rj7kzQ0))
### Guides
1. build guide: [link](https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch/)
2. kernel size for audio: [link](https://stats.stackexchange.com/questions/441847/conv2d-kernel-size-for-audio-related-tasks)

## Understanding
1. Convolution Subsampling: used for sampling the input data, with kernel 3x3 abd stride 2
2. DNN can ignore input topology and resize into column vector, but with the audio feature (mel-spectroram or log mel) these contain low level features that needed to learn so that CNN is suitable for this solution.


# Development
1. ZipFormer: [link](https://arxiv.org/pdf/2310.11230.pdf)
2. ZipFormer paper explained: [link](https://www.youtube.com/watch?v=jvtTs9q1l8w)